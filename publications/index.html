<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Karl Mulligan | publications</title>
  <meta name="description" content="Karl Mulligan is a graduate student in Cognitive Science at Johns Hopkins University.
">

  <link rel="shortcut icon" href="/assets/img/favicon.png">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        Karl Mulligan
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <a class="page-link" href="/blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="/publications/">publications</a>
          
        

        <!-- CV link -->
        <a class="page-link" href="/assets/pdf/cv.pdf">vitae [pdf]</a> 

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description">Publications in reversed chronological order. Generated by jekyll-scholar.</h5>
  </header>

  <article class="post-content publications clearfix">
    <div class="publications">


  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div id="mulligan2021structure">
  <span id="mulligan2021structure"><b>Mulligan, K.</b>, Frank, R., &amp; Linzen, T. (2021). Structure Here, Bias There: Hierarchical Generalization by Jointly Learning Syntactic Transformations. <i>Proceedings of the Society for Computation in Linguistics</i>, <i>4</i>, 125–135.</span>
  
  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/scil-mtl-transformations.pdf" target="_blank">pdf</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>When learning syntactic transformations, children consistently induce structure-dependent generalizations, even though the primary linguistic data may be consistent with both linear and hierarchical rules. What is the source of this inductive bias? In this paper, we use computational models to investigate the hypothesis that evidence for the structure-sensitivity of one syntactic transformation can bias the acquisition of another transformation in favor of a hierarchical rule. We train sequence-to-sequence models based on artificial neural networks to learn multiple syntactic transformations at the same time in a fragment of English; we hold out cases that disambiguate linear and hierarchical rules for one of those transformations, and then test for hierarchical generalization to these held-out sentence types. Consistent with our hypothesis, we find that multitask learning induces a hierarchical bias for certain combinations of tasks, and that this bias is stronger for transformations that share computational building blocks. At the same time, the bias is in general insufficient to lead the learner to categorically acquire the hierarchical generalization for the target transformation.</p>
  </span>
  
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div id="specia2020grounded">
  <span id="specia2020grounded">Specia, L., Barrault, L., Caglayan, O., Duarte, A., Elliott, D., Gella, S., Holzenberger, N., Lala, C., Lee, S. J., Libovicky, J., Madhyastha, P., Metze, F., <b>Mulligan, K.</b>, Ostapenko, A., Palaskar, S., Sanabria, R., Wang, J., &amp; Arora, R. (2020). Grounded Sequence to Sequence Transduction. <i>IEEE Journal of Selected Topics in Signal Processing</i>, <i>14</i>(3), 577–591.</span>
  
  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/ieee-grounded-seq2seq.pdf" target="_blank">pdf</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Speech recognition and machine translation have made major progress over the past decades, providing practical systems to map one language sequence to another. Although multiple modalities such as sound and video are becoming increasingly available, the state-of-the-art systems are inherently unimodal, in the sense that they take a single modality - either speech or text - as input. Evidence from human learning suggests that additional modalities can provide disambiguating signals crucial for many language tasks. In this article, we describe the How2 dataset , a large, open-domain collection of videos with transcriptions and their translations. We then show how this single dataset can be used to develop systems for a variety of language tasks and present a number of models meant as starting points. Across tasks, we find that building multimodal architectures that perform better than their unimodal counterpart remains a challenge. This leaves plenty of room for the exploration of more advanced solutions that fully exploit the multimodal nature of the How2 dataset , and the general direction of multimodal learning with other datasets as well.</p>
  </span>
  
</div>
</li></ol>


</div>

  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2021 Karl Mulligan.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
        Last updated: 30 August 2021.
    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-138668516-1', 'auto');
ga('send', 'pageview');
</script>


  </body>

<link href="https://fonts.googleapis.com/css?family=Cardo&display=swap" rel="stylesheet">

</html>
